{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "z6wcfl5bnjflhfvqbnmzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 526 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 7.6 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=e83c3e36de4f5bc44794c760ea0bccf5d6d5c5cbfcf06cf6d2eabfef95eda482\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9 pymorphy2-dicts-ru-2.4.404381.4453942\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2-0.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2_dicts_ru-2.4.404381.4453942.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/docopt-0.6.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/docopt.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/DAWG_Python-0.7.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2_dicts_ru already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/dawg_python already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/py-env/platform-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Processing ./yandex-datasphere-examples/estimate_quality/stt_metrics-0.12-py3-none-any.whl\n",
      "Collecting pymorphy2\n",
      "  Using cached pymorphy2-0.9-py3-none-any.whl (55 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Using cached pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0 MB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Processing /home/jupyter/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9/docopt-0.6.2-py2.py3-none-any.whl\n",
      "Installing collected packages: pymorphy2-dicts-ru, dawg-python, docopt, pymorphy2, stt-metrics\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9 pymorphy2-dicts-ru-2.4.404381.4453942 stt-metrics-0.12\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2-0.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2_dicts_ru-2.4.404381.4453942.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/docopt-0.6.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/docopt.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/DAWG_Python-0.7.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/pymorphy2_dicts_ru already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/dawg_python already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/py-env/platform-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install pymorphy2\n",
    "%pip install yandex-datasphere-examples/estimate_quality/stt_metrics-0.12-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pdi41sd9ywggooxhxy7wlp"
   },
   "source": [
    "## Оценка качества STT моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7k58oggvwatlffly4zs7ft"
   },
   "source": [
    "Качество распознавания речи на имеющихся данных сильно зависит от выбора конкретной модели. Но чтобы можно было определить, какая из моделей лучше справляется с распознаванием под конкретный бизнес-кейс, требуется правильно построить систему оценки качества распознавания и определить соответствующие метрики.\n",
    "\n",
    "Наиболее популярной метрикой при оценке качества распознавания является метрика WER (Word Error Rate). Эта метрика оценивает похожесть полученного распознавания на некоторый \"эталонный\" пример, как правило получаемый с помощью разметки аудиозаписей с помощью асессоров. Проблема заключается в том, что значение этой метрики может очень сильно варьироваться не только от результатов распознавания, но также и от качества разметки аудиозаписей и самой методологии оценки.\n",
    "\n",
    "В качестве примера можно привести популярную фразу \"алло\", которая может быть размечена как минимум четырьмя различными способами: \"алло\", \"алле\", \"ало\", \"але\". Также качество может падать, если пытаться различать буквы \"ё\" и \"е\", которые эквивалентны с точки зрения большинства моделей распознавания. Наконец, качество может очень сильно зависеть от того, требуется ли нам различать различные формы одних и тех же слов (к примеру, род, падежи существительных, времена глаголов и т.п.).\n",
    "\n",
    "По этой причине мы решили предоставить пользователям свою небольшую библиотеку, которая позволит использовать метрики для оценки качества распознавания с учётом описанных особенностей. На текущий момент эта библиотека поддерживает вычисление метрики WER, однако в дальнейшем библиотеку планируется расширить и другими метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "wu2sr42o5dut1a288k6yo"
   },
   "outputs": [],
   "source": [
    "from stt_metrics import WER, ClusterReferences\n",
    "from stt_metrics.text_transform import Lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "yc0598s63rmasktbb44rah"
   },
   "source": [
    "### Пример использования метрики WER\n",
    "\n",
    "Рассмотрим самый простой вариант использования метрики WER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "4y99e6d3ukju9e49pkxhsr"
   },
   "outputs": [],
   "source": [
    "reference = 'алло добрый день с моей карты только что списали крупную сумму денег хочу заблокировать её'\n",
    "hypothesis = 'але добрый день моей карты только что списал крупную суму денег хочу заблокировать ее'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "lvue2l49urq33ot90clyki"
   },
   "outputs": [],
   "source": [
    "wer = WER()\n",
    "wer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\n",
    "wer_value = wer.calculate_metric(wer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4m2uaxa0p3ubyimm0mwdie"
   },
   "source": [
    "`wer_data` &mdash; специальный объект, который хранит необходимую для вычисления WER информацию, а также предоставляет нам выравнивание двух текстов с указанием отличий. Последняя особенность может быть очень полезна при дальнейшем анализе отличий в распознавании и разметке.\n",
    "\n",
    "Так, на примере ниже мы видим, что значение метрики WER оказывается достаточно высоким. Однако многие ошибки для данного кейса оказываются довольно незначительными. Так, одна ошибка возникает из-за появившейся в разметке буквы \"ё\", ещё одна из ошибок связана с отличием в словах \"але\" и \"алло\", и ещё одна ошибка произошла из-за нераспознанного множественного числа глагола \"списал\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "02las68bbbxjbfcg023x5w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  errors: 5,\n",
      "  hyp_wc: 14,\n",
      "  ref_wc: 15,\n",
      "  diff_hyp: АЛЕ  добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ЕЕ,\n",
      "  diff_ref: АЛЛО добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ЕЁ\n",
      "}\n",
      "WER: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(wer_data)\n",
    "print(f'WER: {wer_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "f3bp6agkr19g0p60fawjh"
   },
   "source": [
    "### Избавление от ошибок\n",
    "\n",
    "#### Удаление артефактов\n",
    "\n",
    "От возможных ошибок первого типа довольно просто избавиться, если заранее провалидировать имеющуюся разметку аудио и избавиться от возможных артефактов. В данном случае такой препроцессинг оказывается довольно простым, хотя в общем случае артефакты могут быть и куда менее очевидными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "sifrl68bdficokkgpze9co"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  errors: 4,\n",
      "  hyp_wc: 14,\n",
      "  ref_wc: 15,\n",
      "  diff_hyp: АЛЕ  добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ее,\n",
      "  diff_ref: АЛЛО добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ее\n",
      "}\n",
      "WER: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "def remove_artifacts(text):\n",
    "    return text.replace('ё', 'е')\n",
    "\n",
    "\n",
    "hypothesis, reference = remove_artifacts(hypothesis), remove_artifacts(reference)\n",
    "\n",
    "wer = WER()\n",
    "wer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\n",
    "wer_value = wer.calculate_metric(wer_data)\n",
    "\n",
    "print(wer_data)\n",
    "print(f'WER: {wer_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "c7bugxl9ftudswqm68cm6p"
   },
   "source": [
    "#### ClusterReferences\n",
    "\n",
    "Ошибки второго типа также могут быть довольно просто исключены, если явно указать наборы синонимичных фраз (ClusterReferences), которые следует воспринимать одинаково:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "qs4zr12523lccn6a5gsy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  errors: 3,\n",
      "  hyp_wc: 14,\n",
      "  ref_wc: 15,\n",
      "  diff_hyp: алло добрый день * моей карты только что СПИСАЛ  крупную СУМУ  денег хочу заблокировать ее,\n",
      "  diff_ref: алло добрый день с моей карты только что СПИСАЛИ крупную СУММУ денег хочу заблокировать ее\n",
      "}\n",
      "WER: 0.2\n"
     ]
    }
   ],
   "source": [
    "cr = ClusterReferences()\n",
    "cr.add_cluster(center='алло', aliases=['ало', 'але', 'алле'])\n",
    "\n",
    "wer = WER(cr=cr)\n",
    "wer_data = wer.get_metric_data(hyp=hypothesis, ref=reference)\n",
    "wer_value = wer.calculate_metric(wer_data)\n",
    "\n",
    "print(wer_data)\n",
    "print(f'WER: {wer_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "a23rpn5h2cn7ndxwj68c"
   },
   "source": [
    "#### Lemmatizer\n",
    "\n",
    "Наконец, можно также постараться избавиться и от ошибок третьего типа, если привести все имеющиеся слова к их леммам. Тем не менее, делать это также следует аккуратно, потому что в лемматизации также могут нуждаться и фразы из ClusterReferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "8hhjier6mvskvi6ndy0j9s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  errors: 2,\n",
      "  hyp_wc: 14,\n",
      "  ref_wc: 15,\n",
      "  diff_hyp: алло добрый день * мой карта только что списать крупный СУМА  деньга хотеть заблокировать она,\n",
      "  diff_ref: алло добрый день с мой карта только что списать крупный СУММА деньга хотеть заблокировать она\n",
      "}\n",
      "WER: 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemm_hypothesis, lemm_reference = lemmatizer.transform(hypothesis), lemmatizer.transform(reference)\n",
    "\n",
    "wer = WER(cr=cr)\n",
    "wer_data = wer.get_metric_data(hyp=lemm_hypothesis, ref=lemm_reference)\n",
    "wer_value = wer.calculate_metric(wer_data)\n",
    "\n",
    "print(wer_data)\n",
    "print(f'WER: {wer_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "virjbqdb3crjuxif3vjlh"
   },
   "source": [
    "### Выводы\n",
    "\n",
    "Если вам просто требуется проверить, что конкретная модель распознавания в среднем делает достаточно мало ошибок в словах, то простая версия метрики WER вполне может подойти вам.\n",
    "\n",
    "Если же вы используете эту метрику для сравнения поведения различных моделей на вашем бизнес-кейсе, то вам может также помочь:\n",
    "\n",
    "* Удаление из разметки и набор распознаваний явных артефактов, которые могут ухудшать значения используемых метрик, не влияя при этом на качество решения конкретной бизнес-задачи\n",
    "\n",
    "* Использование ClusterReference'ов для \"склейки\" одинаковых по сути распознаваний. Так можно склеить различные варианты распознавания фраз типа \"алло\", а также распознавания фраз с пробелами (наподобие \"контр страйк\" и \"контрстрайк\")\n",
    "\n",
    "* Лемматизация слов, если для нас не важны их окончания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "89d2tvzxin4f1g7k4vbv5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "7c29683c-86a5-421a-8a0c-90189ba53ee8"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
